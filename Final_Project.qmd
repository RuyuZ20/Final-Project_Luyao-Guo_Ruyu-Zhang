title: "Dap2 Final project-Housing Burden Among Older Adults"
author: "Luyao Guo, Ruyu Zhang"
date: "2024-11-20"
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
output:
  echo: false
  eval: false
---

Data Dictionary:
YEAR  Census year 
SAMPLE	IPUMS sample identifier
SERIAL	Household serial number 
CBSERIAL	Original Census Bureau household serial number
HHWT	Household weight
CLUSTER	Household cluster for variance estimation
COUNTYFIP	County (FIPS code, identifiable counties only)
CITY	City (identifiable cities only)
STRATA	Household strata for variance estimation
GQ	Group quarters status
NFAMS	Number of families in household
PERNUM	Person number in sample unit 
PERWT	  Person weight
RELATE	Relationship to household head
SEX	  Sex
MARST	Marital status
RACE	Race
EDUC	Educational attainment
EMPSTAT	Employment status
FTOTINC	Total family income
POVERTY	Poverty status
INCEARN	Total personal earned income
STATEFIP	State (FIPS code)
AGE	    Age
RENTGRS	Monthly gross rent
INCTOT	Total personal income
DIFFMOB	Independent living difficulty
DIFFCARE	Self-care difficulty

```{python}
import pandas as pd
import altair as alt
import numpy as np
import warnings
import os
warnings.filterwarnings('ignore')
alt.renderers.enable("png")
```

Step 1: Data Cleaning and Initial Exploration

(Partner 1): 
1. Handle placeholder values and clean the data.
2. Identify and replace placeholder values like 9999999 with NaN.
3. Filter the dataset for individuals aged 65+.
4. Create a new column for Housing_Burden (e.g., RENTGRS / INCTOT * 100).

Deliverables:
Cleaned data ready for analysis.
Summary of missing values and cleaned variables.

```{python}
base_path = '/Users/apple/Desktop/class/Dap-2/problem_sets'
path_1=os.path.join(base_path,"usa_00003.csv")
df_raw_data = pd.read_csv(path_1)
```

```{python}
print(df_raw_data.head())

# Print the column names
print(df_raw_data.columns.tolist())
```

Extract columns as needed

```{python}
#1
columns_needed = ['YEAR', 'STATEFIP', 'AGE', 'RENTGRS', 'INCTOT', 'DIFFMOB', 'DIFFCARE']
cleaned_data = pd.read_csv(file_path, usecols=columns_needed)
print(cleaned_data.info())
```

```{python}
#2
# Replace NaN
placeholder_values = [9999999, 0]
cleaned_data.replace(placeholder_values, np.nan, inplace=True)

# Check NaN
print(cleaned_data.isnull().sum())

```


 Drop Columns with Excessive Missing Values

```{python}
#3
# drop missing values rentgers
cleaned_data = cleaned_data.dropna(subset=['RENTGRS'])
print(cleaned_data.isnull().sum())

#4
# Fill in other missing values with default values
cleaned_data['AGE'].fillna(cleaned_data['AGE'].median(), inplace=True)
cleaned_data['INCTOT'].fillna(0, inplace=True)
cleaned_data['DIFFMOB'].fillna(0, inplace=True)
cleaned_data['DIFFCARE'].fillna(0, inplace=True)

#5 Filter for individuals aged 65 and older
cleaned_data = cleaned_data[cleaned_data['AGE'] >= 65]

#6 Create Housing Burden column *
cleaned_data['Housing_Burden'] = (cleaned_data['RENTGRS'] / cleaned_data['INCTOT']) * 100
# Handle infinite values
cleaned_data['Housing_Burden'].replace([np.inf, -np.inf], np.nan, inplace=True)  
 # Assume 0 burden for undefined cases
cleaned_data['Housing_Burden'].fillna(0, inplace=True) 

# 7: Summary of missing values and cleaned variables
print("Summary of missing values after cleaning:")
print(cleaned_data.isnull().sum())

print("\nData overview after cleaning:")
print(cleaned_data.describe())

```

Partner 2: Perform initial data exploration.
1. Calculate descriptive statistics for key variables (AGE, INCTOT, RENTGRS, Housing_Burden, DIFFMOB, DIFFCARE).
2. Add state abbreviation column by matching state FIPS to state abbreviations.
3. Group data by STATEFIP and calculate average housing burden for older adults.
4. Draw a bar chart to visualize the distribution of housing burdens by state.

Deliverables:
Summary statistics 
cleaned_data.csv
State-level table showing average housing burden and total elderly population.

```{python}
# Descriptive statistics calculation
stats_summary = cleaned_data[['AGE', 'INCTOT', 'RENTGRS',
                              'Housing_Burden', 'DIFFMOB', 'DIFFCARE']].describe().round(2)
print(stats_summary)
```

```{python}
path_2 = os.path.join(base_path, "states_fips.csv")
df_states = pd.read_csv(path_2)
df_states=df_states.rename(columns={'Postal':'State_name'})
# Match state FIPS to state abbreviation
cleaned_data = pd.merge(cleaned_data, df_states,
                        left_on='STATEFIP', right_on='FIPS', how='left')
cleaned_data = cleaned_data.drop('FIPS', axis=1)
```

```{python}
# Save cleaned dataframe as .csv
cleaned_data.to_csv('cleaned_data.csv')

```

```{python}
# Aggregate average housing burden and total elderly population per state
state_summary_hb = cleaned_data.groupby('State_name').agg(
    avg_housing_burden=('Housing_Burden', 'mean'),
    total_elderly_population=('AGE', 'count')
).reset_index()
print(state_summary_hb)
```

```{python}
# Sort by average housing burden
state_summary_sorted_hb = state_summary_hb.sort_values(
    by='avg_housing_burden', ascending=False).reset_index(drop=True)
print(state_summary_sorted_hb)

# Bar chart for distribution of housing burden by state
chart_housing_burden = alt.Chart(state_summary_sorted_hb).mark_bar().encode(
    x=alt.X('avg_housing_burden:Q', title='Average Housing Burden (%)'),
    y=alt.Y('State_name:N', title='State Abbr.', sort='-x'),
    tooltip=['State_name', 'avg_housing_burden']
).configure_axis(
    labelFontSize=6,
    titleFontSize=10
).properties(
    title='Average Housing Burden Distribution by State (2023)',
    width=700,
    height=500
)

chart_housing_burden.display()
```

Step 2: Geographic Mapping with State Shapefiles

(Partner 1):
1. Load the U.S. state boundary shapefile and ensure relevant columns are formatted 
consistently for merging.
2. Merge the state boundary GeoDataFrame with the state-level dataset to integrate 
housing burden data for older adults.
3. Create a choropleth map to highlight state-level variations in average housing burden, 
with an optimized legend and layout for better readability.
```{python}
import geopandas as gpd
import matplotlib.pyplot as plt
# 1: Load the shapefile
shapefile_path = '/Users/apple/Desktop/class/Dap-2/problem_sets/tl_2023_us_state/tl_2023_us_state.shp'
gdf_states = gpd.read_file(shapefile_path)
gdf_states['STATEFP'] = gdf_states['STATEFP'].astype(int)

# 2: Ensure `state_summary_hb` includes `STATEFP` for merging
state_summary_hb = state_summary_hb.rename(columns={"State_name": "State", "STATEFIP": "STATEFP"})
state_summary_hb['STATEFP'] = state_summary_hb['STATEFP'].astype(int)

# 3: Merge `state_summary_hb` with `gdf_states`
merged_gdf = gdf_states.merge(state_summary_hb, on='STATEFP', how='left')
# 4: Plot the choropleth map
fig, ax = plt.subplots(1, 1, figsize=(24, 12))
map_plot = merged_gdf.plot(
    column='avg_housing_burden',
    cmap='OrRd',
    legend=True,
    legend_kwds={
        'label': "Average Housing Burden (%)",
        'orientation': "horizontal",
        'shrink': 0.6,
        'pad': 0.05
    },
    edgecolor='black',
    ax=ax
)
ax.set_title("Average Housing Burden by State (2023)", fontsize=24)
ax.set_axis_off()
# Adjust layout 
plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.1)
plt.show()
```

